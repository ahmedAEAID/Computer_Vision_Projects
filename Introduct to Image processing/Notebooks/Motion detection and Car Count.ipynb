{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e36b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "from time import sleep\n",
    "# from tracker import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5206b",
   "metadata": {},
   "source": [
    "### First Project Motion Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3fdad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vtest.avi') \n",
    "# frame_width = int( cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# frame_height =int( cap.get( cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# print(frame_width, frame_height)\n",
    "\n",
    "fourcc =cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter('output Motion Detection.avi',fourcc, 5.0,(1280,720))\n",
    "\n",
    "_, frame1 = cap.read()\n",
    "_, frame2 = cap.read()\n",
    "\n",
    "while cap.isOpened():\n",
    "    movement = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(movement, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur = cv2.GaussianBlur(gray, (5,5),0)\n",
    "    _, thresh = cv2.threshold(blur, 60, 255, cv2.THRESH_BINARY)\n",
    "    dilation = cv2.dilate(thresh,None, iterations= 5)\n",
    "    contours,_ = cv2.findContours(dilation, cv2.RETR_TREE,\n",
    "                                  cv2.CHAIN_APPROX_NONE)\n",
    "#     cv2.drawContours(frame1,contours,-1,(0,255,0),1)\n",
    "\n",
    "    for contour in contours:  \n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contour) < 900:\n",
    "            continue\n",
    "        cv2.rectangle(frame1 , (x,y),(x+w, y+h),(0,255,0),2)\n",
    "        cv2.putText(frame1, f'states: Movement',(10,30),\n",
    "                    cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,1,(0,0,255),2)\n",
    "    image = cv2.resize(frame1, (1280,720))\n",
    "    output.write(image)\n",
    "    cv2.imshow(\"gray\", gray)\n",
    "    cv2.imshow(\"dilation\", dilation)\n",
    "    cv2.imshow(\"feed\", frame1)\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "    if cv2.waitKey(40) == 27 or not ret:\n",
    "\n",
    "        break  \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = cv2.VideoWriter('ahmedd.mp4',\n",
    "#                          cv2.VideoWriter_fourcc(*'XVID'),\n",
    "#                          20, (250,250))\n",
    "\n",
    "# tracker = EuclideanDistTracker()\n",
    "# cap = cv2.VideoCapture(\"tracking Object videos/highway.mp4\")\n",
    "\n",
    "# object_detector = cv2.createBackgroundSubtractorMOG2(history=100,\n",
    "#                                                      varThreshold=50) # if history is big number it will be hight \n",
    "\n",
    "# while True:\n",
    "\n",
    "#     ret, frame = cap.read()      \n",
    "#     if ret is not True:   \n",
    "#         break    \n",
    "#     height, width, _ = frame.shape\n",
    "    \n",
    "#     roi = frame[340: 720,500: 800]\n",
    "\n",
    "#     mask = object_detector.apply(roi)\n",
    "#     mask = cv2.GaussianBlur(mask, (5,5),0)\n",
    "#     _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "#     mask = cv2.dilate(mask , None, iterations = 5)\n",
    "    \n",
    "#     contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     detections = []\n",
    "#     for cnt in contours:    \n",
    "#         area = cv2.contourArea(cnt)       \n",
    "#         if area > 100:       \n",
    "#             x, y, w, h = cv2.boundingRect(cnt)\n",
    "#             detections.append([x, y, w, h])              \n",
    "\n",
    "#     boxes_ids = tracker.update(detections)\n",
    "#     for box_id in boxes_ids:\n",
    "#         x, y, w, h, id = box_id\n",
    "#         cv2.putText(roi, str(id), (x, y), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "#         cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "#     cv2.imshow(\"roi\", roi)\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "#     cv2.imshow(\"Mask\", mask)\n",
    "#     result.write(frame)\n",
    "    \n",
    "#     key = cv2.waitKey(30)\n",
    "    \n",
    "#     if key == 27:\n",
    "#         break        \n",
    "\n",
    "# result.release()\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bafdd",
   "metadata": {},
   "source": [
    "### Car Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09b2f55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of cars detected : 1\n",
      "No. of cars detected : 2\n",
      "No. of cars detected : 3\n",
      "No. of cars detected : 4\n",
      "No. of cars detected : 5\n",
      "No. of cars detected : 6\n",
      "No. of cars detected : 7\n",
      "No. of cars detected : 8\n",
      "No. of cars detected : 9\n",
      "No. of cars detected : 10\n",
      "No. of cars detected : 11\n",
      "No. of cars detected : 12\n"
     ]
    }
   ],
   "source": [
    "INTERESTED_W = 80\n",
    "INTERESTED_H = 90\n",
    "h_line = 550\n",
    "offset = 6\n",
    "\n",
    "cap = cv2.VideoCapture('tracking Object videos/CarStaticBackground.mp4')\n",
    "fourcc= cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter('countcars.mp4', fourcc, 10, (1280,720))\n",
    "BGS = cv2.createBackgroundSubtractorMOG2()\n",
    "count = 0\n",
    "def get_center(x,y,w,h):\n",
    "    w1 = int(w/2)\n",
    "    h1 = int(h/2)\n",
    "    center = (x+w1,y+h1)\n",
    "    return center\n",
    "def get_mask(img):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5),3)\n",
    "    mask = BGS.apply(blur)\n",
    "    dilation = cv2.dilate(mask, np.ones((3,3)))\n",
    "    \n",
    "    return dilation\n",
    "centers = []\n",
    "while True:\n",
    "    ret, frame= cap.read()\n",
    "    if ret:\n",
    "        mask = get_mask(frame)\n",
    "        contours,_ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "        cv2.line(frame, (25, h_line), (1200, h_line), (176, 130, 39), 2)\n",
    "        for contour in contours:\n",
    "            (x,y,w,h) = cv2.boundingRect(contour)\n",
    "            \n",
    "#             validarea_contour = cv2.contourArea(contour) >= 1000\n",
    "            validarea_contour = (w >= INTERESTED_W) and (h >= INTERESTED_H)\n",
    "            if not validarea_contour:\n",
    "                continue\n",
    "            cv2.rectangle(frame , (x,y),(x+w,y+h), (0,255,0),2)\n",
    "            center = get_center(x,y,w,h)\n",
    "            centers.append(center)\n",
    "            cv2.circle(frame, center,4, (0, 0, 255), -1)\n",
    "            \n",
    "            for x,y in centers :\n",
    "                if h_line+offset > y > h_line - offset :\n",
    "                    count += 1\n",
    "                    cv2.line(frame, (25, h_line), (1200, h_line), (0, 127, 255), 3)\n",
    "                    centers.remove((x, y)) \n",
    "                    print(\"No. of cars detected : \" + str(count))\n",
    "                \n",
    "        cv2.putText(frame, \"VEHICLE COUNT : \"+str(count), (320, 70),cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 255), 4)\n",
    "        image = cv2.resize(frame, (1280,720))\n",
    "        output.write(image)\n",
    "        cv2.imshow(\"Video Original\", frame)\n",
    "        cv2.imshow(\" Detectar \", mask)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7262f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee57b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
